global:
  # -- configures DNS service name
  dnsService: "coredns"

# the below fields are only used to avoid context errors from helm
serviceAccount:
  create: true
enterprise:
  enabled: false

hpa:
  querier:
    enabled: true
    minReplicas: 1
    maxReplicas: 3
    targetCPUUtilizationPercentage: 90
    targetMemoryUtilizationPercentage: 90
    behavior:
      scaleDown:
        policies:
          - periodSeconds: 120
            type: Percent
            value: 10
        stabilizationWindowSeconds: 600
      scaleUp:
        policies:
          - periodSeconds: 120
            type: Percent
            value: 50
          - periodSeconds: 120
            type: Pods
            value: 15
        stabilizationWindowSeconds: 60
  distributor:
    enabled: true
    minReplicas: 1
    maxReplicas: 3
    targetCPUUtilizationPercentage: 90
    targetMemoryUtilizationPercentage: 90
    behavior:
      scaleDown:
        policies:
          - periodSeconds: 600
            type: Percent
            value: 10

kedaAutoscaling:
  querier:
    enabled: true
    horizontalPodAutoscalerConfig:
      behavior:
        scaleDown:
          policies:
            - periodSeconds: 120
              type: Percent
              value: 10
          stabilizationWindowSeconds: 600
        scaleUp:
          policies:
            - periodSeconds: 120
              type: Percent
              value: 50
            - periodSeconds: 120
              type: Pods
              value: 15
          stabilizationWindowSeconds: 60
    triggers:
    - type: memory
      metricType: Utilization
      metadata:
        # equivalent of targetMemoryUtilizationPercentage in HPA
        value: "90"
    - type: cpu
      metricType: Utilization
      metadata:
        # equivalent of targetCPUUtilizationPercentage in HPA
        value: "90"
    pollingInterval: 30
    cooldownPeriod: 300
    minReplicas: 1
    maxReplicas: 3
  distributor:
    enabled: false
    horizontalPodAutoscalerConfig:
      behavior:
        scaleDown:
          policies:
          - periodSeconds: 600
            type: Percent
            value: 10
    triggers:
    - type: memory
      metricType: Utilization
      metadata:
        value: "90"
    - type: cpu
      metricType: Utilization
      metadata:
        value: "90"
    pollingInterval: 30
    cooldownPeriod: 300
    minReplicas: 1
    maxReplicas: 3
  gateway:
    enabled: false
    horizontalPodAutoscalerConfig: {}
    triggers:
    - type: memory
      metricType: Utilization
      metadata:
        value: "90"
    - type: cpu
      metricType: Utilization
      metadata:
        value: "90"
    pollingInterval: 30
    cooldownPeriod: 300
    minReplicas: 1
    maxReplicas: 3

# Default configuration for HA alertmanager
alertmanager:
  replicas: 3
  affinity:
    podAntiAffinity:
      preferredDuringSchedulingIgnoredDuringExecution:
      - weight: 100
        podAffinityTerm:
          labelSelector:
            matchExpressions:
            - key: app.kubernetes.io/component
              operator: In
              values:
              - alertmanager
          topologyKey: "kubernetes.io/hostname"

mimir:
  # You can make the whole chart ineffective by setting this one to "false"
  enabled: true

  nameOverride: ""
  fullnameOverride: ""

  image:
    repository: gsoci.azurecr.io/giantswarm/mimir

  rbac:
    podSecurityPolicy:
      readOnlyRootFilesystem: false
      additionalVolumes:
        - hostPath
        - projected

  metaMonitoring:
    serviceMonitor:
      # We need to se this value to have the mixin rules work.
      interval: 30s

  priorityClass:
    enabled: true
    create: true
    # The value is only relevant when using the custom priority class.
    value: 500000000
    name: mimir

  alertmanager:
    enabled: false

  distributor:
    replicas: 1

    resources:
      requests:
        cpu: 100m
        memory: 512Mi

    securityContext:
      seccompProfile:
        type: RuntimeDefault

  ingester:
    # -- Total number of replicas for the ingester across all availability zones
    # If ingester.zoneAwareReplication.enabled=false, this number is taken as is.
    # Otherwise each zone starts `ceil(replicas / number_of_zones)` number of pods.
    #   E.g. if 'replicas' is set to 4 and there are 3 zones, then 4/3=1.33 and after rounding up it means 2 pods per zone are started.
    replicas: 3

    # -- If mimir.priorityClass.create is set to true, the following field must match mimir.priorityClass.name.
    priorityClassName: mimir

    statefulSet:
      enabled: true

    resources:
      requests:
        cpu: "200m"
        memory: 4Gi

    # -- Pod Disruption Budget for ingester, this will be applied across availability zones to prevent losing redundancy
    podDisruptionBudget:
      maxUnavailable: 1

    securityContext:
      seccompProfile:
        type: RuntimeDefault

    verticalAutoscaling:
      enabled: true
      # -- These values will be overriden in the config repos
      minAllowed:
        cpu: 100m
        memory: 2Gi
      maxAllowed:
        cpu: 1
        memory: 10Gi

  overrides_exporter:
    enabled: true
    replicas: 1

    resources:
      requests:
        cpu: 100m
        memory: 128Mi

    securityContext:
      seccompProfile:
        type: RuntimeDefault

  ruler:
    enabled: true
    replicas: 1
    # Additional ruler container arguments, e.g. log level (debug, info, warn, error)
    extraArgs: {}
      # log.level: debug

    resources:
      requests:
        cpu: 100m
        memory: 128Mi

    securityContext:
      seccompProfile:
        type: RuntimeDefault

  querier:
    replicas: 2

    resources:
      requests:
        cpu: 100m
        memory: 128Mi

    securityContext:
      seccompProfile:
        type: RuntimeDefault

  query_frontend:
    replicas: 1

    resources:
      requests:
        cpu: 100m
        memory: 128Mi

    securityContext:
      seccompProfile:
        type: RuntimeDefault

  query_scheduler:
    enabled: true
    replicas: 2

    resources:
      requests:
        cpu: 100m
        memory: 128Mi

    securityContext:
      seccompProfile:
        type: RuntimeDefault

  store_gateway:
    # -- Total number of replicas for the store-gateway across all availability zones
    # If store_gateway.zoneAwareReplication.enabled=false, this number is taken as is.
    # Otherwise each zone starts `ceil(replicas / number_of_zones)` number of pods.
    #   E.g. if 'replicas' is set to 4 and there are 3 zones, then 4/3=1.33 and after rounding up it means 2 pods per zone are started.
    replicas: 1

    resources:
      requests:
        cpu: 100m
        memory: 512Mi

    # -- Pod Disruption Budget for store-gateway, this will be applied across availability zones to prevent losing redundancy
    podDisruptionBudget:
      maxUnavailable: 1

    securityContext:
      seccompProfile:
        type: RuntimeDefault

    persistentVolume:
      enableRetentionPolicy: true
      whenDeleted: Retain
      whenScaled: Delete

  compactor:
    replicas: 1

    resources:
      requests:
        cpu: 100m
        memory: 512Mi

    securityContext:
      seccompProfile:
        type: RuntimeDefault

    persistentVolume:
      enableRetentionPolicy: true
      whenDeleted: Retain
      whenScaled: Delete

  memcached:
    image:
      repository: gsoci.azurecr.io/giantswarm/memcached

    podSecurityContext:
      runAsNonRoot: true
      runAsUser: 65534
      seccompProfile:
        type: RuntimeDefault

  memcachedExporter:
    # -- Whether memcached metrics should be exported
    enabled: true

    image:
      repository: gsoci.azurecr.io/giantswarm/memcached-exporter

  chunks-cache:
    # -- Specifies whether memcached based chunks-cache should be enabled
    enabled: false
    verticalAutoscaling:
      enabled: false
      minAllowed:
        cpu: 100m
        memory: 500Mi
      maxAllowed:
        cpu: 1
        memory: 2Gi

  index-cache:
    # -- Specifies whether memcached based index-cache should be enabled
    enabled: false

  metadata-cache:
    # -- Specifies whether memcached based metadata-cache should be enabled
    enabled: false

  results-cache:
    # -- Specifies whether memcached based results-cache should be enabled
    enabled: false

  # -- Setting for the Grafana Rollout Operator https://github.com/grafana/helm-charts/tree/main/charts/rollout-operator
  rollout_operator:
    enabled: false

  minio:
    enabled: false

  nginx:
    # -- Specifies whether nginx should be enabled
    enabled: false

  # -- A reverse proxy deployment that is meant to receive traffic for Mimir or GEM.
  # When enterprise.enabled is true the GEM gateway is deployed. Otherwise, it is an nginx.
  # Options except those under gateway.nginx apply to both versions - nginx and GEM gateway.
  gateway:
    # -- The gateway is deployed by default for enterprise installations (enterprise.enabled=true).
    # Toggle this to have it deployed for non-enterprise installations too.
    enabledNonEnterprise: true

    resources:
      requests:
        cpu: 100m
        memory: 100Mi

    autoscaling:
      enabled: true
      minReplicas: 1
      maxReplicas: 3
      targetCPUUtilizationPercentage: 90
      targetMemoryUtilizationPercentage: 90

    # -- Number of replicas for the Deployment
    replicas: 1

    securityContext:
      seccompProfile:
        type: RuntimeDefault

    nginx:
      image:
        registry: gsoci.azurecr.io
        repository: giantswarm/nginx-unprivileged
